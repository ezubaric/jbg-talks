@inproceedings{Bianchi2020PretrainingIA,
	title = "Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence",
	author = "Bianchi, Federico  and
	Terragni, Silvia  and
	Hovy, Dirk",
	booktitle = acl,
	month = aug,
	year = "2021",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2021.acl-short.96",
	doi = "10.18653/v1/2021.acl-short.96",
	pages = "759--766",
}


@inproceedings{bleiLatentDirichletAllocation2003,
 author = {David M. Blei and
Andrew Y. Ng and
Michael I. Jordan},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle = nips,
 editor = {Thomas G. Dietterich and
Suzanna Becker and
Zoubin Ghahramani},
 publisher = {{MIT} Press},
 title = {{L}atent {D}irichlet {A}llocation},
 url = {https://proceedings.neurips.cc/paper/2001/hash/296472c9542ad4d4788d543508116cbc-Abstract.html},
 year = {2001}
}

@article{brysbaert2016words,
 abstract = {Based on an analysis of the literature and a large scale crowdsourcing experiment, we estimate that an average 20-year-old native speaker of American English knows 42,000 lemmas and 4,200 non-transparent multiword expressions, derived from 11,100 word families. The numbers range from 27,000 lemmas for the lowest 5% to 52,000 for the highest 5%. Between the ages of 20 and 60, the average person learns 6,000 extra lemmas or about one new lemma every 2 days. The knowledge of the words can be as shallow as knowing that the word exists. In addition, people learn tens of thousands of inflected forms and proper nouns (names), which account for the substantially high numbers of ‘words known’ mentioned in other publications.},
 author = {Brysbaert, Marc and Stevens, Michaël and Mandera, Paweł and Keuleers, Emmanuel},
 doi = {10.3389/fpsyg.2016.01116},
 issn = {1664-1078},
 journal = {Frontiers in Psychology},
 title = {How Many Words Do We Know? {P}ractical Estimates of Vocabulary Size Dependent on Word Definition, the Degree of Language Input and the Participant’s Age},
 url = {https://www.frontiersin.org/article/10.3389/fpsyg.2016.01116},
 volume = {7},
 year = {2016}
}

@article{burkhardtDecouplingSparsitySmoothness2019,
 abstract = {Recent work on variational autoencoders (VAEs) has enabled the development of generative topic models using neural networks. Topic models based on latent Dirichlet allocation (LDA) successfully use the Dirichlet distribution as a prior for the topic and word distributions to enforce sparseness. However, there is a trade-off between sparsity and smoothness in Dirichlet distributions. Sparsity is important for a low reconstruction error during training of the autoencoder, whereas smoothness enables generalization and leads to a better loglikelihood of the test data. Both of these properties are encoded in the Dirichlet parameter vector. By rewriting this parameter vector into a product of a sparse binary vector and a smoothness vector, we decouple the two properties, leading to a model that features both a competitive topic coherence and a high log-likelihood. Efficient training is enabled using rejection sampling variational inference for the reparameterization of the Dirichlet distribution. Our experiments show that our method is competitive with other recent VAE topic models.},
 author = {Burkhardt, Sophie and Kramer, Stefan},
 journal = {Journal of Machine Learning Research},
 language = {en},
 number = {131},
 title = {Decoupling {{Sparsity}} and {{Smoothness}} in the {{Dirichlet Variational Autoencoder Topic Model}}},
 volume = {20},
 year = {2019}
}

@inproceedings{Card2020WithLP,
 address = {Online},
 author = {Card, Dallas  and
Henderson, Peter  and
Khandelwal, Urvashi  and
Jia, Robin  and
Mahowald, Kyle  and
Jurafsky, Dan},
 booktitle = emnlp,
 doi = {10.18653/v1/2020.emnlp-main.745},
 publisher = {Association for Computational Linguistics},
 title = {With Little Power Comes Great Responsibility},
 url = {https://www.aclweb.org/anthology/2020.emnlp-main.745},
 year = {2020}
}

@inproceedings{Chuang2014ComputerAssistedCA,
 author = {Jason Chuang and J. Wilkerson and R. Weiss and D. Tingley and Brandon M Stewart},
 title = {Computer-Assisted Content Analysis : Topic Models for Exploring Multiple Subjective Interpretations},
 journal = {Advances in Neural Information Processing Systems Workshop on Human-Propelled Machine Learning},
 year = {2014}
}

@article{diengTopicModelingEmbedding2019,
 author = {Dieng, Adji B.  and
Ruiz, Francisco J. R.  and
Blei, David M.},
 doi = {10.1162/tacl_a_00325},
 booktitle=tacl,
 title = {Topic Modeling in Embedding Spaces},
 url = {https://www.aclweb.org/anthology/2020.tacl-1.29},
 volume = {8},
 year = {2020}
}

@inproceedings{Dodge2019ShowYW,
 address = {Hong Kong, China},
 author = {Dodge, Jesse  and
Gururangan, Suchin  and
Card, Dallas  and
Schwartz, Roy  and
Smith, Noah A.},
 booktitle = emnlp,
 doi = {10.18653/v1/D19-1224},
 publisher = {Association for Computational Linguistics},
 title = {Show Your Work: Improved Reporting of Experimental Results},
 url = {https://www.aclweb.org/anthology/D19-1224},
 year = {2019}
}

@inproceedings{doogan-buntine-2021-topic,
 address = {Online},
 author = {Doogan, Caitlin  and
Buntine, Wray},
 booktitle = naacl,
 publisher = {Association for Computational Linguistics},
 title = {Topic Model or Topic Twaddle? {R}e-evaluating Semantic Interpretability Measures},
 url = {https://www.aclweb.org/anthology/2021.naacl-main.300},
 year = {2021}
}

@inproceedings{Eisenstein2011SparseAG,
 author = {Jacob Eisenstein and
Amr Ahmed and
Eric P. Xing},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle = icml,
 editor = {Lise Getoor and
Tobias Scheffer},
 publisher = {Omnipress},
 title = {Sparse Additive Generative Models of Text},
 url = {https://icml.cc/2011/papers/534\_icmlpaper.pdf},
 year = {2011}
}

@inproceedings{Figurnov2018ImplicitRG,
 author = {Mikhail Figurnov and
Shakir Mohamed and
Andriy Mnih},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle = nips,
 editor = {Samy Bengio and
Hanna M. Wallach and
Hugo Larochelle and
Kristen Grauman and
Nicol{\`{o}} Cesa{-}Bianchi and
Roman Garnett},
 title = {Implicit Reparameterization Gradients},
 url = {https://proceedings.neurips.cc/paper/2018/hash/92c8c96e4c37100777c7190b76d28233-Abstract.html},
 year = {2018}
}

@inproceedings{Gao2021TopicMF,
 address = {online},
 author = {Gao, Shuang  and
Pandya, Shivani  and
Agarwal, Smisha  and
Sedoc, Jo{\~a}o},
 booktitle = {Proceedings of the 12th International Workshop on Health Text Mining and Information Analysis},
 publisher = {Association for Computational Linguistics},
 title = {Topic Modeling for Maternal Health Using {R}eddit},
 url = {https://www.aclweb.org/anthology/2021.louhi-1.8},
 year = {2021}
}

@article{george2014legal,
 author = {Clint P . George and Sahil Puri and Daisy Zhe Wang and Joseph Wilson and William Hamilton},
 journal = {Proceedings of the 27th International FLAIRS Conference},
 title = {{SMART} Electronic Legal Discovery via Topic Modeling},
 year = {2014}
}

@inproceedings{Goodfellow2014GenerativeAN,
 author = {Ian J. Goodfellow and
Jean Pouget{-}Abadie and
Mehdi Mirza and
Bing Xu and
David Warde{-}Farley and
Sherjil Ozair and
Aaron C. Courville and
Yoshua Bengio},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle = nips,
 editor = {Zoubin Ghahramani and
Max Welling and
Corinna Cortes and
Neil D. Lawrence and
Kilian Q. Weinberger},
 title = {Generative Adversarial Nets},
 url = {https://proceedings.neurips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html},
 year = {2014}
}

@article{Griffiths2004FindingST,
 author = {T. Griffiths and M. Steyvers},
 journal = {Proceedings of the National Academy of Sciences of the United States of America},
 title = {Finding scientific topics},
 volume = {101},
 year = {2004}
}

@inproceedings{Gupta2019DocumentIN,
 author = {Pankaj Gupta and
Yatin Chaudhary and
Florian Buettner and
Hinrich Sch{\"{u}}tze},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle =aaai,
 doi = {10.1609/aaai.v33i01.33016505},
 publisher = {{AAAI} Press},
 title = {Document Informed Neural Autoregressive Topic Models with Distributional
Prior},
 url = {https://doi.org/10.1609/aaai.v33i01.33016505},
 year = {2019}
}

@inproceedings{hoyle-etal-2020-improving,
 address = {Online},
 author = {Hoyle, Alexander Miserlis  and
Goel, Pranav  and
Resnik, Philip},
 booktitle = emnlp,
 doi = {10.18653/v1/2020.emnlp-main.137},
 publisher = {Association for Computational Linguistics},
 title = {{I}mproving {N}eural {T}opic {M}odels using {K}nowledge {D}istillation},
 url = {https://www.aclweb.org/anthology/2020.emnlp-main.137},
 year = {2020}
}

@inproceedings{Jankowiak2018PathwiseDB,
 author = {Martin Jankowiak and
Fritz Obermeyer},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle = icml,
 editor = {Jennifer G. Dy and
Andreas Krause},
 publisher = {{PMLR}},
 series = {Proceedings of Machine Learning Research},
 title = {Pathwise Derivatives Beyond the Reparameterization Trick},
 url = {http://proceedings.mlr.press/v80/jankowiak18a.html},
 volume = {80},
 year = {2018}
}

@article{Joo2020DirichletVA,
title = {Dirichlet Variational Autoencoder},
journal = {Pattern Recognition},
volume = {107},
pages = {107514},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107514},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320303174},
author = {Weonyoung Joo and Wonsung Lee and Sungrae Park and Il-Chul Moon},
}

@inproceedings{kingmaAutoEncodingVariationalBayes2014,
 author = {Diederik P. Kingma and
Max Welling},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle = iclr,
 editor = {Yoshua Bengio and Yann LeCun},
 title = {Auto-Encoding Variational Bayes},
 url = {http://arxiv.org/abs/1312.6114},
 year = {2014}
}

@article{Lin2020CopulaGN,
 author = {Lihui Lin and Hongyu Jiang and Yanghui Rao},
 journal = sigir,
 title = {Copula Guided Neural Topic Modelling for Short Texts},
 year = {2020}
}

@article{Liu2016AnOO,
 author = {L. Liu and L. Tang and Wen Dong and Shaowen Yao and Wei Zhou},
 journal = {SpringerPlus},
 title = {An overview of topic modeling and its current applications in bioinformatics},
 volume = {5},
 year = {2016}
}

@article{mann1947u,
 author = {H. B. Mann and D. R. Whitney},
 doi = {10.1214/aoms/1177730491},
 journal = {The Annals of Mathematical Statistics},
 number = {1},
 publisher = {Institute of Mathematical Statistics},
 title = {{On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other}},
 url = {https://doi.org/10.1214/aoms/1177730491},
 volume = {18},
 year = {1947}
}

@article{marche2012humanities,
  author          = {Stephen Marche},
  title           = {Literature Is not Data: Against Digital Humanities},
  journal         = {LA Review of Books},
  year            = {2012},
  url  = {https://lareviewofbooks.org/article/literature-is-not-data-against-digital-humanities/}
}

@article{allington2016humanities,
  author          = {Daniel Allington and Sarah Brouillette and David Golumbia},
  title           = {Neoliberal Tools (and Archives): A Political History of Digital Humanities},
  journal         = {LA Review of Books},
  year            = {2016},
  url = {https://lareviewofbooks.org/article/neoliberal-tools-archives-political-history-digital-humanities/}
}

@unpublished{McCallumMALLET,
 author = {Andrew Kachites McCallum},
 note = {http://mallet.cs.umass.edu},
 title = {{MALLET}: A Machine Learning for Language Toolkit},
 year = {2002}
}

@article{meeks2012digital,
 author = {Meeks, Elijah and Weingart, Scott B},
 journal = {Journal of Digital Humanities},
 number = {1},
 title = {The digital humanities contribution to topic modeling},
 volume = {2},
 year = {2012}
}

@article{schmidt2012words,
 author = {Benjamin M Schmidt},
 journal = {Journal of Digital Humanities},
 number = {1},
 title = {Words Alone: Dismantling Topic Models in the Humanities},
 volume = {2},
 year = {2012},
 url = {http://journalofdigitalhumanities.org/2-1/words-alone-by-benjamin-m-schmidt/}
}

@inproceedings{merityPointerSentinelMixture2017,
 author = {Stephen Merity and
Caiming Xiong and
James Bradbury and
Richard Socher},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle = iclr,
 publisher = {OpenReview.net},
 title = {Pointer Sentinel Mixture Models},
 url = {https://openreview.net/forum?id=Byj72udxe},
 year = {2017}
}

@article{MOHR2013545,
 author = {John W. Mohr and Petko Bogdanov},
 doi = {https://doi.org/10.1016/j.poetic.2013.10.001},
 issn = {0304-422X},
 journal = {Poetics},
 note = {Special Issue on Topic Models and the Cultural Sciences},
 number = {6},
 title = {Introduction—Topic models: What they are and why they matter},
 url = {https://www.sciencedirect.com/science/article/pii/S0304422X13000685},
 volume = {41},
 year = {2013}
}

@inproceedings{Nan2019TopicMW,
 address = {Florence, Italy},
 author = {Nan, Feng  and
Ding, Ran  and
Nallapati, Ramesh  and
Xiang, Bing},
 booktitle=acl,
 doi = {10.18653/v1/P19-1640},
 publisher = {Association for Computational Linguistics},
 title = {Topic Modeling with {W}asserstein Autoencoders},
 url = {https://www.aclweb.org/anthology/P19-1640},
 year = {2019}
}

@inproceedings{Panwar2020TANNTMTA,
 author = {Madhur Panwar and Shashank Shailabh and Milan Aggarwal and Balaji Krishnamurthy},
 booktitle=acl,
 title = {{TAN-NTM}: Topic Attention Networks for Neural Topic Modeling},
 volume = {abs/2012.01524},
 year = {2020}
}

@inproceedings{poursabzi-sangdeh-etal-2016-alto,
 address = {Berlin, Germany},
 author = {Poursabzi-Sangdeh, Forough  and
Boyd-Graber, Jordan  and
Findlater, Leah  and
Seppi, Kevin},
 booktitle=acl,
 doi = {10.18653/v1/P16-1110},
 publisher = {Association for Computational Linguistics},
 title = {{ALTO}: Active Learning with Topic Overviews for Speeding Label Induction and Document Labeling},
 url = {https://www.aclweb.org/anthology/P16-1110},
 year = {2016}
}

@article{powerSim,
author = {A. H. Feiveson},
title ={Power by Simulation},
journal = {The Stata Journal},
year = {2002},
doi = {10.1177/1536867X0200200201},

URL = { 
        https://doi.org/10.1177/1536867X0200200201
    
},
eprint = { 
        https://doi.org/10.1177/1536867X0200200201
    
}
,
    abstract = { This paper describes how to write Stata programs to estimate the power of virtually any statistical test that Stata can perform. Examples given include the t test, Poisson regression, Cox regression, and the nonparametric rank-sum test. }
}


@inproceedings{Rder2015ExploringTS,
 author = {Michael R{\"{o}}der and
Andreas Both and
Alexander Hinneburg},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle = {Proceedings of the Eighth {ACM} International Conference on Web Search
and Data Mining, {WSDM} 2015, Shanghai, China, February 2-6, 2015},
 doi = {10.1145/2684822.2685324},
 editor = {Xueqi Cheng and
Hang Li and
Evgeniy Gabrilovich and
Jie Tang},
 publisher = {{ACM}},
 title = {Exploring the Space of Topic Coherence Measures},
 url = {https://doi.org/10.1145/2684822.2685324},
 year = {2015}
}

@inproceedings{rehurek_lrec,
 address = {Valletta, Malta},
 author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
 booktitle = {{Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks}},
 day = {22},
 language = {English},
 publisher = {ELRA},
 title = {{Software Framework for Topic Modelling with Large Corpora}},
 year = {2010}
}

@inproceedings{Roberts2013TheST,
 author = {M. E. Roberts and Brandon M Stewart and D. Tingley and E. Airoldi},
 booktitle = {ICONIP 2013},
 title = {The structural topic model and applied social science},
 year = {2013}
}

@article{sandhaus2008new,
 author = {Sandhaus, Evan},
 journal = {Linguistic Data Consortium, Philadelphia},
 number = {12},
 title = {The new york times annotated corpus},
 volume = {6},
 year = {2008}
}

@article{Schofield2016ComparingAT,
 author = {Schofield, Alexandra  and
Mimno, David},
 doi = {10.1162/tacl_a_00099},
 booktitle=tacl,
 title = {Comparing Apples to Apple: The Effects of Stemmers on Topic Models},
 url = {https://www.aclweb.org/anthology/Q16-1021},
 volume = {4},
 year = {2016}
}

@article{schuirmann1987comparison,
 author = {Schuirmann, Donald J},
 journal = {Journal of pharmacokinetics and biopharmaceutics},
 number = {6},
 publisher = {Springer},
 title = {A comparison of the two one-sided tests procedure and the power approach for assessing the equivalence of average bioavailability},
 volume = {15},
 year = {1987}
}

@inproceedings{Srivastava2017AutoencodingVI,
 author = {Akash Srivastava and
Charles Sutton},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 booktitle=iclr,
 publisher = {OpenReview.net},
 title = {Autoencoding Variational Inference For Topic Models},
 url = {https://openreview.net/forum?id=BybtVK9lg},
 year = {2017}
}

@inproceedings{Stiennon2020LearningTS,
 author = {Nisan Stiennon and L. Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan J. Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},
 booktitle=nips,
 title = {Learning to summarize from human feedback},
 volume = {abs/2009.01325},
 year = {2020}
}

@article{Strathern1997ImprovingRA,
 author = {M. Strathern},
 journal = {European Review},
 title = {‘Improving ratings’: audit in the British University system},
 volume = {5},
 year = {1997}
}

@inproceedings{Tian2020LearningVM,
 author = {Runzhi Tian and Yong-yi Mao and Richong Zhang},
 booktitle = emnlp,
 title = {Learning {VAE-LDA} Models with Rounded Reparameterization Trick},
 year = {2020}
}

@article{underwoodGenealogy2017,
 abstract = {It has recently become common to describe all empirical approaches to literature as subfields of digital humanities. This essay argues that distant reading has a largely distinct genealogy stretching back many decades before the advent of the internet – a genealogy that is not for the most part centrally concerned with computers. It would be better to understand this field as a conversation between literary studies and social science, inititated by scholars like Raymond Williams and Janice Radway, and moving slowly toward an explicitly experimental method. Candor about the social-scientific dimension of distant reading is needed now, in order to refocus a research agenda that can drift into diffuse exploration of digital tools. Clarity on this topic might also reduce miscommunication between distant readers and digital humanists.},
 author = {Underwood, {William E}},
 issn = {1938-4122},
 journal = {Digital Humanities Quarterly},
 language = {English (US)},
 number = {2},
 publisher = {Alliance of Digital Humanities Organisations},
 title = {A Genealogy of Distant Reading},
 volume = {11},
 year = {2017}
}

@inproceedings{Wang2019ATMAT,
 author = {Rui Wang and Deyu Zhou and Yulan He},
 booktitle=acl,
 title = {{ATM}: Adversarial-neural Topic Model},
 volume = {abs/1811.00265},
 year = {2020}
}

@book{wellek2010testing,
 abstract = {While continuing to focus on methods of testing for two-sided equivalence, Testing Statistical Hypotheses of Equivalence and Noninferiority, Second Edition},
 author = {Wellek, Stefan},
 doi = {10.1201/EBK1439808184},
 isbn = {978-0-429-09267-1},
 language = {en},
 publisher = {Chapman and Hall/CRC},
 title = {Testing {Statistical} {Hypotheses} of {Equivalence} and {Noninferiority}},
 url = {https://www.taylorfrancis.com/books/9780429092671},
 urldate = {2019-08-13},
 year = {2010}
}

@inproceedings{terragni2020octis,
    title={{OCTIS}: Comparing and Optimizing Topic Models is Simple!},
    author={Terragni, Silvia and Fersini, Elisabetta and Galuzzi, Bruno Giovanni and Tropeano, Pietro and Candelieri, Antonio},
    year={2021},
    booktitle={Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations},
    month = apr,
    year = "2021",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2021.eacl-demos.31",
    pages = "263--270",
}

@inproceedings{Wu2020ShortTT,
 author = {Xiaobao Wu and C. Li and Yan Zhu and Yishu Miao},
 booktitle = emnlp,
 title = {Short Text Topic Modeling with Topic Distribution Quantization and Negative Sampling Decoder},
 year = {2020}
}

@article{Yang2020GraphAT,
 author = {L. Yang and Fan Wu and Junhua Gu and C. Wang and Xiaochun Cao and Di Jin and Y. Guo},
 journal = {Proceedings of The Web Conference 2020},
 title = {Graph Attention Topic Modeling Network},
 year = {2020}
}

@article{Zhao2020NeuralTM,
 author = {He Zhao and Dinh Phung and Viet Huynh and Trung Le and W. Buntine},
 booktitle = iclr,
 title = {Neural Topic Model via Optimal Transport.},
 year = {2021}
}

@inproceedings{zhao2021neural,
 author = {He Zhao and Dinh Phung and Viet Huynh and Trung Le and Wray Buntine},
 booktitle = {International Conference on Learning Representations},
 title = {Neural Topic Model via Optimal Transport},
 url = {https://openreview.net/forum?id=Oos98K9Lv-k},
 year = {2021}
}

@inproceedings{Zhao2021TopicMM,
 author = {He Zhao and Dinh Q. Phung and Viet Huynh and Y. Jin and Lan Du and W. Buntine},
 title = {Topic Modeling Meets Deep Neural Networks: A Survey},
 booktitle = {Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI-21): Survey Track},
 volume = {abs/2103.00498},
 year = {2021}
}

@inproceedings{Zhou2020NeuralTM,
 author = {Deyu Zhou and Xuemeng Hu and Rui Wang},
 booktitle=emnlp,
 title = {Neural Topic Modeling by Incorporating Document Relationship Graph},
 volume = {abs/2009.13972},
 year = {2020}
}

@book{Zipf49,
 author = {Zipf, George K.},
 keywords = {},
 publisher = {Addison-Wesley},
 title = {Human Behaviour and the Principle of Least Effort},
 year = {1949}
}

@article{Silveira2018TopicMU,
    title={Topic Modeling using Variational Auto-Encoders with Gumbel-Softmax and Logistic-Normal Mixture Distributions},
    author={Denys Silveira and A. Carvalho and Marco Cristo and Marie-Francine Moens},
    journal={2018 International Joint Conference on Neural Networks (IJCNN)},
    year={2018},
    pages={1-8} }

@inproceedings{Peng2018NeuralST,
    title={Neural Sparse Topical Coding},
    author={Min Peng and Qianqian Xie and H. Wang and Y. Zhang and Xiuzhen Zhang and Jimin Huang and Gang Tian},
    booktitle=acl,
    year={2018} }

@article{Ding2018CoherenceAwareNT,
    title={Coherence-Aware Neural Topic Modeling},
    author={Ran Ding and Ramesh Nallapati and Bing Xiang},
    booktitle = acl,
    year={2018},
    volume={abs/1809.02687} }
@inproceedings{Zhang2018WHAIWH,
    title={WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling},
    author={Hao Zhang and B. Chen and Dandan Guo and M. Zhou},
    booktitle=iclr,
    year={2018} }

@article{Jung2017ContinuousST,
    title={Continuous Semantic Topic Embedding Model Using Variational Autoencoder},
    author={Namkyu Jung and H. Choi},
    journal={ArXiv},
    year={2017},
    volume={abs/1711.08870} }

@article{Nguyen2015ImprovingTM,
    title={Improving Topic Models with Latent Feature Word Representations},
    author={Dat Quoc Nguyen and R. Billingsley and Lan Du and Mark Johnson},
    booktitle=tacl,
    year={2015},
    volume={3},
    pages={299-313} }

@inproceedings{Isonuma2020TreeStructuredNT,
    title={Tree-Structured Neural Topic Model},
    author={Masaru Isonuma and Junichiro Mori and Danushka Bollegala and I. Sakata},
    booktitle=acl,
    year={2020} }

@inproceedings{Wang2020NeuralTM,
    title={Neural Topic Modeling with Bidirectional Adversarial Training},
    author={Rui Wang and Xuemeng Hu and Deyu Zhou and Yulan He and Yuxuan Xiong and Chenchen Ye and Haiyang Xu},
    booktitle=acl,
    year={2020} }

@inproceedings{Wu2020NeuralMC,
    title={Neural Mixed Counting Models for Dispersed Topic Discovery},
    author={Jiemin Wu and Yanghui Rao and Zusheng Zhang and Haoran Xie and Qing Li and Fu Lee Wang and Ziye Chen},
    booktitle=acl,
    year={2020} }

@article{Feng2020ContextRN,
    title={Context Reinforced Neural Topic Modeling over Short Texts},
    author={Jiachun Feng and Zusheng Zhang and Cheng Ding and Yanghui Rao and Haoran Xie},
    journal={ArXiv},
    year={2020},
    volume={abs/2008.04545} }

@article{Thompson2020TopicMW,
    title={Topic Modeling with Contextualized Word Representation Clusters},
    author={Laure Thompson and D. Mimno},
    journal={ArXiv},
    year={2020},
    volume={abs/2010.12626} }

@inproceedings{Hu2020NeuralTM,
    title={Neural Topic Modeling with Cycle-Consistent Adversarial Training},
    author={Xuemeng Hu and Rui Wang and Deyu Zhou and Yuxuan Xiong},
    booktitle=emnlp,
    year={2020} }

@inproceedings{Rezaee2020ADV,
    title={A Discrete Variational Recurrent Topic Model without the Reparametrization Trick},
    author={Mehdi Rezaee and Francis Ferraro},
    booktitle=nips,
    year={2020},
    volume={abs/2010.12055} }

@article{Ning2020NonparametricTM,
    title={Nonparametric Topic Modeling with Neural Inference},
    author={Xuefei Ning and Y. Zheng and Zhuxi Jiang and Y. Wang and H. Yang and J. Huang},
    journal={Neurocomputing},
    year={2020},
    volume={399},
    pages={296-306} }

@inproceedings{Gupta2019textTOvecDC,
    title={{textTOvec}: Deep Contextualized Neural Autoregressive Models of Language with Distributed Compositional Prior},
    author={Pankaj Gupta and Yatin Chaudhary and F. Buettner and Hinrich Sch{\"u}tze},
    booktitle = iclr,
    year={2019},
    url = {https://openreview.net/forum?id=rkgoyn09KQ}}

@article{Lin2019SparsemaxAR,
    title={Sparsemax and Relaxed Wasserstein for Topic Sparsity},
    author={Tianyi Lin and Zhiyue Hu and Xin Guo},
    journal={Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
    year={2019} }

@inproceedings{Card2018NeuralMF,
    title={Neural Models for Documents with Metadata},
    author={D. Card and Chenhao Tan and Noah A. Smith},
    booktitle=acl,
    year={2018} }

@inproceedings{He2018InteractionAwareTM,
    title={Interaction-Aware Topic Model for Microblog Conversations through Network Embedding and User Attention},
    author={Ruifang He and X. Zhang and Di Jin and Longbiao Wang and J. Dang and Xiangang Li},
    booktitle=coling,
    year={2018} }

@inproceedings{Zhu2018GraphBTMGE,
    title={GraphBTM: Graph Enhanced Autoencoded Variational Inference for Biterm Topic Model},
    author={Qile Zhu and Zheng Feng and Xiaolin Li},
    booktitle=emnlp,
    year={2018} }

@inproceedings{Zhao2018DirichletBN,
    title={Dirichlet belief networks for topic structure learning},
    author={He Zhao and Lan Du and Wray L. Buntine and M. Zhou},
    booktitle = nips, 
    year={2018},
    volume={abs/1811.00717} }

@inproceedings{Miao2017DiscoveringDL,
    title={Discovering Discrete Latent Topics with Neural Variational Inference},
    author={Yishu Miao and Edward Grefenstette and P. Blunsom},
    booktitle=icml,
    year={2017},
    volume={abs/1706.00359} }

@article{Miao2016NeuralVI,
    title={Neural Variational Inference for Text Processing},
    author={Yishu Miao and L. Yu and P. Blunsom},
    booktitle=icml,
    year={2016},
    volume={abs/1511.06038} }

@inproceedings{Gui2019NeuralTM,
    title={Neural Topic Model with Reinforcement Learning},
    author={Lin Gui and Jia-Wei Leng and Gabriele Pergola and Y. Zhou and Ruifeng Xu and Yulan He},
    booktitle=emnlp,
    year={2019} }

@inproceedings{Liu2019NeuralVC,
  title={Neural Variational Correlated Topic Modeling},
  author={Luyang Liu and Heyan Huang and Yang Gao and Yongfeng Zhang and X. Wei},
  booktitle=www,
  year={2019}
}