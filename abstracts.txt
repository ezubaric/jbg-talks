
Jordan Boyd-Graber (UMD) will be presenting work entitled "Cooperative and Competitive Machine Learning through Question Answering":

Abstract:
My research goal is to create machine learning algorithms that are
interpretable to humans, that can understand human strengths and
weaknesses, and can help humans improve themselves.  In this talk,
I'll discuss how we accomplish this through a trivia game called quiz
bowl. These questions are written so that they can be interrupted by
someone who knows more about the answer; that is, harder clues are at
the start of the question and easier clues are at the end of the
question: a player must decide when it has enough information to "buzz
in". Our system to answer quiz bowl questions depends on two parts: a
system to identify the answer to questions and to determine when to
buzz.  We discuss how deep averaging networks---fast neural bag of
words models---can help us answer questions quickly using diverse
training data (previous questions, raw text of novels, Wikipedia
pages) to determine the right answer and how deep reinforcement
learning can help us determine when to buzz.

More importantly, however, this setting also helps us build systems to
adapt in cooperation and competition with humans.  In competition, we
are also able to understand the skill sets of our competitors to
adjust our strategy to optimize our performance against players using
a deep mixture of experts opponent model.  The game of quiz bowl also
allows opportunities to better understand interpretability in deep
learning models to *help* human players perform better with machine
cooperation.  This cooperation helps us with a related task,
simultaneous machine translation.

Finally, I'll discuss opportunities for broader participation through
open human-computer competitions:
http://hcqa.boydgraber.org/

Jordan Boyd-Graber is an associate professor in the University of
Maryland's Computer Science Department, iSchool, UMIACS, and Language
Science Center. Jordan's research focus is in applying machine
learning and Bayesian probabilistic models to problems that help us
better understand social interaction or the human cognitive
process. He and his students have won "best of" awards at NIPS (2009,
2015), NAACL (2016), and CoNLL (2015), and Jordan won the British
Computing Society's 2015 Karen Sp√§rk Jones Award and a 2017 NSF CAREER
award. His research has been funded by DARPA, IARPA, NSF, NCSES, ARL,
NIH, and Lockheed Martin and has been featured by CNN, Huffington
Post, New York Magazine, and the Wall Street Journal.

===========================================

Computational Modeling of Relationships, Spin, and Betrayal

Computational approaches allow us to understand how text encodes
latent social factors.  My talk focuses on recent work that
attempts to use unannotated or found annotations to better understand
relationships in the real world, in fiction, and in games.  First,
I'll discuss a probabilistic model that attempts to predict the
political polarization of a speaker based on how they frame policy
issues.  Based on data from the US congress, we describe the Tea Party
movement and its relationship to mainstream Republicans.  Next, I'll
discuss a deep dictionary learning approach to categorize the
relationships between fictional characters over time.  We'll show that
this approach improves over topic model baselines in both prediction
and human interpretability.  Finally, I'll discuss work to detect
deception in an online game called Diplomacy and which clues can
predict betrayal.

================================================================

Title: Thinking on your Feet: Reinforcement Learning for Incremental Language Tasks

Abstract: 

In this talk, I'll discuss two real-world language applications that require "thinking on your feet": synchronous machine translation (or "machine simultaneous interpretation") and question answering (when questions are revealed one piece at a time).  In both cases, effective algorithms for these tasks must interrupt the input stream and decide when to provide output.

Synchronous machine translation is when a sentence is being produced one word at a time in a foreign language and we want to produce a translation in English simultaneously (i.e., with as little delay between a foreign language word and its English translation). This is particularly difficult in verb-final languages like German or Japanese, where an English translation can barely begin until the verb is seen. Effective translation thus requires predictions of unseen elements of the sentence (e.g., the main verb in German and Japanese, or relative clauses in Japanese, or post-positions in Japanese). We use reinforcement learning to decide when to trust our verb predictions. It must learn to balance incorrect translation versus timely translations, and must use those predictions to translate the sentence.

For question answering, we use a specially designed dataset that challenges humans: a trivia game called quiz bowl. These questions are written so that they can be interrupted by someone who knows more about the answer; that is, harder clues are at the start of the question and easier clues are at the end of the question. We create a novel neural network system to predict answers from incomplete questions and use reinforcement learning to decide when to guess.  We are able to answer questions earlier in the questions than most college trivia contestants.

================================================================

Title:

Big Data Analysis with Topic Models: Human Interaction and Social
Science Applications

Abstract:

A common information need is to understand large, unstructured
datasets: millions of e-mails during e-discovery, a decade worth of
science correspondence, or a day's tweets.  In the last decade, topic
models have become a common tool for navigating such datasets.  This
talk investigates the foundational research that allows successful
tools for these data exploration tasks: how to know when you have an
effective model of the dataset; how to correct bad models; how to
measure topic model effectiveness; and how to detect framing and spin
using these techniques.  After introducing topic models, I argue why
traditional measures of topic model quality---borrowed from machine
learning---are inconsistent with how topic models are actually used.
In response, I describe interactive topic modeling, a technique that
enables users to impart their insights and preferences to models in a
principled, interactive way.  I will then address measuring topic
model effectiveness in real-world tasks.  Finally, I'll discuss
ongoing collaborations with political scientists to use these
techniques to detect spin and framing in political and online
interactions.

================================================================

Opening the Black Box of Machine Learning: Interactive, Interpretable Interfaces for Exploring Linguistic Tasks

Abstract: Machine learning is ubiquitous, but most users treat it as a
black box: a handy tool that suggests purchases, flags spam, or
autocompletes text. I present qualities that ubiquitous machine
learning should have to allow for a future filled with fruitful,
natural interactions with humans: interpretability, interactivity, and
an understanding of human qualities. After introducing these
properties, I present machine learning applications that begin to
fulfill these desirable properties. I begin with a traditional
information processing task---making sense and categorizing large
document collections---and show that machine learning methods can
provide interpretable, efficient techniques to categorize large
document collections with a human in the loop. From there, I turn to
language-based games that require machines and humans to compete and
cooperate and discuss how this can improve and measure
interpretability in machine learning.
